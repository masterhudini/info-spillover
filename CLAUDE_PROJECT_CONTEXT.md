# Claude Code - Projekt Info Spillover - Kontekst i Zasady

## ğŸ¯ **Cel GÅ‚Ã³wny Projektu**
Analiza spillover informacyjnego miÄ™dzy subredditami cryptocurrency a cenami kryptowalut przy uÅ¼yciu hierarchicznych modeli sentiment analysis z grafowymi sieciami neuronowymi (GNN).

Badanie oparte na metodologii Diebold-Yilmaz spillover analysis z nowoczesnymi technikami deep learning.

---

## ğŸ›ï¸ **Podstawowe Zasady Pracy**

### âš ï¸ **NAJWAÅ»NIEJSZA ZASADA**
> **"Å¼adnych gÅ‚upich hot fixÃ³w, tylko dokÅ‚adnie, przeczytaj dokumentacjÄ™, ÅºrÃ³dÅ‚a naukowe itp."**

**Zawsze:**
1. **Czytaj dokumentacjÄ™** - sprawdÅº wszystkie pliki README, konfiguracje, komentarze w kodzie
2. **Analizuj caÅ‚oÅ›ciowo** - zrozum architekturÄ™ przed wprowadzeniem zmian
3. **Szukaj naukowego uzasadnienia** - kaÅ¼da implementacja powinna byÄ‡ oparta na solid theoretical foundation
4. **Testuj systematycznie** - nie rÃ³b zmian bez testowania
5. **UÅ¼ywaj wÅ‚aÅ›ciwych narzÄ™dzi i wzorcÃ³w** - nie wynajduj koÅ‚a na nowo

**Nigdy nie:**
- RÃ³b quick fixes bez zrozumienia problemu
- Wprowadzaj temporary patches
- Ignoruj bÅ‚Ä™dÃ³w/warnings
- Zmieniaj konfiguracji bez uzasadnienia

---

## ğŸ”§ **Åšrodowisko Pracy**

### **Wirtualne Åšrodowisko**
```bash
# ZAWSZE aktywuj przed pracÄ…:
source ~/venvs/info_spillover/bin/activate

# Lokalizacja: /home/Hudini/venvs/info_spillover/
# NIE tworz nowych venv - uÅ¼ywaj istniejÄ…cego
```

### **Testy i Pipeline**
```bash
# Szybki test pipeline:
source ~/venvs/info_spillover/bin/activate && timeout 120 python -m src.main_pipeline --config test_pipeline_quick.yaml --single-config

# GÅ‚Ã³wny config: /home/Hudini/projects/info_spillover/experiments/configs/config.yaml
```

---

## ğŸ—„ï¸ **Dane i Å¹rÃ³dÅ‚a**

### **Hierarchia WaÅ¼noÅ›ci Å¹rÃ³deÅ‚ Danych:**

1. **BigQuery (NAJWAÅ»NIEJSZE)** ğŸ¥‡
   - Google Cloud BigQuery tables
   - `project.info_spillover.posts_comments`
   - `project.info_spillover.crypto_prices`
   - **Zawsze sprawdÅº BigQuery przed lokalnymi danymi**

2. **Lokalne Dane (backup/dev)** ğŸ¥ˆ
   - `/home/Hudini/projects/info_spillover/data/`
   - CSV files, JSON exports
   - UÅ¼ywaj tylko gdy BigQuery niedostÄ™pne

3. **Syntetyczne Dane (tylko do testÃ³w)** ğŸ¥‰
   - Generowane automatycznie dla dev/test
   - NIE uÅ¼ywaj do produkcji

### **DostÄ™p do BigQuery:**
```python
from src.data.bigquery_client import BigQueryClient
client = BigQueryClient(project_id="your-project", dataset_id="info_spillover")
```

---

## ğŸ—ï¸ **Architektura Modeli**

### **Model Hierarchiczny (GÅ‚Ã³wny)**

```
Hierarchical Model Architecture:
â”œâ”€â”€ Level 1: Subreddit-specific LSTMs
â”‚   â”œâ”€â”€ SubredditLSTM dla kaÅ¼dego subreddita
â”‚   â”œâ”€â”€ Input: sentiment features (24 dims typically)
â”‚   â””â”€â”€ Output: local predictions + embeddings
â”œâ”€â”€ Level 2: Graph Neural Network
â”‚   â”œâ”€â”€ SpilloverGNN (GAT/GCN layers)
â”‚   â”œâ”€â”€ Input: node embeddings + spillover network
â”‚   â””â”€â”€ Output: cross-subreddit spillover effects
â””â”€â”€ Fusion Layer: Final predictions
    â”œâ”€â”€ Combines L1 + L2 outputs
    â””â”€â”€ Multi-task loss (MSE + CrossEntropy)
```

### **Kluczowe Komponenty:**
- `HierarchicalDataModule` - data loading & batching
- `HierarchicalBatchSampler` - multi-subreddit sampling
- `HierarchicalCollator` - custom batch construction
- `HierarchicalDataset` - PyTorch compatibility wrapper

---

## ğŸ“Š **Diebold-Yilmaz Spillover Analysis**

### **Metodologia:**
1. **VAR Model Fitting** - Vector Autoregression na sentiment data
2. **Variance Decomposition** - dekompozycja wariancji prediction errors
3. **Spillover Network Creation** - macierz spillover jako graf
4. **NetworkX Integration** - graf jako input do GNN

### **Kluczowe Pliki:**
- `src/analysis/diebold_yilmaz_spillover.py`
- Implementuje Diebold & Yilmaz (2012) methodology
- Input: multi-variate time series per subreddit
- Output: directed graph z spillover weights

---

## ğŸ”„ **Pipeline Flow**

### **GÅ‚Ã³wny PrzepÅ‚yw:**
```
1. Data Collection (BigQuery)
   â†“
2. Feature Engineering (sentiment, technical indicators)
   â†“
3. Hierarchical Data Processing (time series preparation)
   â†“
4. Diebold-Yilmaz Spillover Analysis (network creation)
   â†“
5. Hierarchical Model Training (LSTM + GNN)
   â†“
6. MLFlow Logging & Evaluation
```

### **Entry Points:**
- `src/main_pipeline.py` - gÅ‚Ã³wny pipeline
- `src/training_pipeline.py` - tylko training
- Konfig: `experiments/configs/config.yaml`

---

## ğŸ§¬ **Hierarchical Model - Technical Details**

### **Zrefactorowana Architektura (2024-12):**

#### **Data Flow:**
```
Raw Data â†’ HierarchicalDataset â†’ HierarchicalBatchSampler â†’ HierarchicalCollator â†’ Model
```

#### **Batch Structure:**
```python
# Batch format z HierarchicalCollator:
batch = (subreddit_data, graph_data, targets)

subreddit_data: Dict[str, torch.Tensor]  # {subreddit: sequences}
graph_data: GraphData object             # .subreddit_names, .edge_index, .edge_attr
targets: torch.Tensor                    # Concatenated targets (variable length)
```

#### **RobustnoÅ›Ä‡:**
- **Edge Validation**: sprawdza bounds dla graph indices
- **Fallback Mechanisms**: L1-only predictions gdy GNN fails
- **Dynamic Graph Creation**: tylko dla dostÄ™pnych subreddits
- **Tensor Shape Handling**: rÃ³Å¼ne dÅ‚ugoÅ›ci sequences per subreddit

---

## ğŸ› **Common Issues & Solutions**

### **"not enough values to unpack"**
- âŒ Problem: batch unpacking errors
- âœ… RozwiÄ…zanie: sprawdÅº HierarchicalCollator return format

### **"'Tensor' object has no attribute 'items'"**
- âŒ Problem: model expects dict, gets tensor
- âœ… RozwiÄ…zanie: sprawdÅº subreddit_data structure

### **"input.size(-1) must be equal to input_size"**
- âŒ Problem: LSTM dimension mismatch
- âœ… RozwiÄ…zanie: sprawdÅº input_dim w model initialization

### **"index X is out of bounds for dimension 0"**
- âŒ Problem: graph edge indices > num_nodes
- âœ… RozwiÄ…zanie: edge validation + fallback graph creation

### **BigQuery Authentication Errors**
```bash
# SprawdÅº credentials:
gcloud auth application-default login
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account.json"
```

---

## ğŸ“¦ **Dependencies & Tools**

### **Core Libraries:**
- `pytorch-lightning` - model training framework
- `torch-geometric` - GNN operations
- `networkx` - graph processing
- `google-cloud-bigquery` - data access
- `mlflow` - experiment tracking
- `dvc` - data versioning

### **Development:**
- `pytest` - testing framework
- `black` - code formatting
- `ruff` - linting

---

## ğŸ”¬ **Scientific Background**

### **Key Papers:**
1. **Diebold & Yilmaz (2012)** - "Better to give than to receive: Predictive directional measurement of volatility spillovers"
2. **Li et al. (2015)** - "Gated Graph Sequence Neural Networks"
3. **VeliÄkoviÄ‡ et al. (2017)** - "Graph Attention Networks"

### **Research Context:**
- **Information Spillover Theory**: how sentiment flows between markets
- **Behavioral Finance**: social media impact on trading
- **Network Effects**: interconnectedness in crypto markets

---

## ğŸš€ **MLFlow Integration**

### **Experiment Tracking:**
```python
# Auto-logging enabled w pipeline
mlflow.pytorch.autolog()

# Metrics tracked:
# - training_loss, val_loss
# - model parameters & gradients
# - spillover network statistics
# - prediction accuracy & correlation
```

### **Model Registry:**
- Models automatycznie rejestrowane po training
- Versioning based on performance metrics
- Integration z BigQuery dla model serving

---

## ğŸ“ **Project Structure Overview**

```
info_spillover/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                     # Data processing
â”‚   â”‚   â”œâ”€â”€ bigquery_client.py   # BigQuery integration
â”‚   â”‚   â””â”€â”€ hierarchical_data_processor.py
â”‚   â”œâ”€â”€ models/                   # Model implementations
â”‚   â”‚   â””â”€â”€ hierarchical_models.py  # Main hierarchical model
â”‚   â”œâ”€â”€ analysis/                 # Analysis modules
â”‚   â”‚   â””â”€â”€ diebold_yilmaz_spillover.py
â”‚   â””â”€â”€ main_pipeline.py         # Entry point
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ configs/                 # Configuration files
â”œâ”€â”€ data/                        # Local data (backup)
â””â”€â”€ notebooks/                   # Jupyter analysis
```

---

## âœ… **Validation Checklist**

Przed kaÅ¼dÄ… implementacjÄ…:

- [ ] PrzeczytaÅ‚em dokumentacjÄ™ zwiÄ…zanÄ… z obszarem
- [ ] ZrozumiaÅ‚em scientific background
- [ ] SprawdziÅ‚em existing patterns w kodzie
- [ ] PrzetestowaÅ‚em z venv activation
- [ ] SprawdziÅ‚em BigQuery availability
- [ ] UruchomiÅ‚em tests przed commit
- [ ] Code follows project conventions
- [ ] No temporary fixes lub hot patches

---

## ğŸ“ **Development History Notes**

### **Major Refactoring (Dec 2024):**
- **Problem**: Batch unpacking failures w hierarchical model
- **Root Cause**: Architectural mismatch - model expected dict, DataLoader returned tensors
- **Solution**: Complete refactoring z HierarchicalBatchSampler + HierarchicalCollator + HierarchicalDataset
- **Result**: Robust multi-subreddit batching z proper error handling

### **Lessons Learned:**
1. **Architecture-first approach** beats quick fixes
2. **Graph validation** critical dla GNN stability
3. **Tensor shape consistency** requires careful collation
4. **Fallback mechanisms** essential dla robust production models

---

*Dokument zaktualizowany: December 2024*
*NastÄ™pna aktualizacja: po kolejnych major changes*